{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "Y = tf.placeholder(\"float\", [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer + Pooling #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w     = get_weights([3, 3, 1, 32])\n",
    "conv1 = tf.nn.relu(tf.nn.conv2d(X, w, strides=[1, 1, 1, 1], padding='SAME'))             # shape=(?, 28, 28, 32)\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  # shape=(?, 14, 14, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer + Pooling #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w     = get_weights([3, 3, 32, 64])\n",
    "conv2 = tf.nn.relu(tf.nn.conv2d(pool1, w, strides=[1, 1, 1, 1], padding='SAME'))         # shape=(?, 14, 14, 64)\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  # shape=(?, 7, 7, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w        = get_weights([7*7*64, 625])\n",
    "reshaped = tf.reshape(pool2, [-1, 7*7*64]) # shape=(?, 4*4*128)\n",
    "fullycon = tf.nn.relu(tf.matmul(reshaped, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w          = get_weights([625, 10])\n",
    "output     = tf.matmul(fullycon, w)\n",
    "predict_op = tf.argmax(output, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss       = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, Y))\n",
    "accuracy   = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output, 1), tf.argmax(Y, 1)), tf.float32))\n",
    "train_op   = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Validation split\n",
    "valid_ratio = float(10)/55\n",
    "train_pairs = zip(mnist.train.images, mnist.train.labels)\n",
    "random.shuffle(train_pairs)\n",
    "train_X, train_Y = zip(*train_pairs[int(valid_ratio*len(train_pairs)):])\n",
    "valid_X, valid_Y = zip(*train_pairs[:int(valid_ratio*len(train_pairs))])\n",
    "\n",
    "# Test pairs\n",
    "test_X, test_Y = mnist.test.images, mnist.test.labels\n",
    "\n",
    "# Reshape\n",
    "train_X = np.array(train_X).reshape(-1, 28, 28, 1)  # 28x28x1 images\n",
    "valid_X = np.array(valid_X).reshape(-1, 28, 28, 1)  # 28x28x1 images\n",
    "test_X  = test_X.reshape(-1, 28, 28, 1)   # 28x28x1 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 45000\n",
      "Validation: 10000\n",
      "Test: 10000\n"
     ]
    }
   ],
   "source": [
    "print 'Training:', len(train_X)\n",
    "print 'Validation:', len(valid_X)\n",
    "print 'Test:', len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100:  0.842286\n",
      "Step 200:  0.265457\n",
      "Step 300:  0.184413\n",
      "Step 400:  0.13271\n",
      "Step 500:  0.12951\n",
      "Step 600:  0.108051\n",
      "Step 700:  0.104047\n",
      "End of epoch 1:\n",
      "Training loss: 0.251543 Validation loss: 0.10487 Test loss: 0.0876171\n",
      "Validation accuracy: 96.7248% Test accuracy: 97.1454%\n",
      "\n",
      "Step 100:  0.0832287\n",
      "Step 200:  0.0844818\n",
      "Step 300:  0.0777482\n",
      "Step 400:  0.0647151\n",
      "Step 500:  0.0649353\n",
      "Step 600:  0.0609844\n",
      "Step 700:  0.0606653\n",
      "End of epoch 2:\n",
      "Training loss: 0.07101 Validation loss: 0.0679193 Test loss: 0.0563342\n",
      "Validation accuracy: 97.7764% Test accuracy: 98.1571%\n",
      "\n",
      "Step 100:  0.0491016\n",
      "Step 200:  0.0578753\n",
      "Step 300:  0.04956\n",
      "Step 400:  0.048476\n",
      "Step 500:  0.045424\n",
      "Step 600:  0.0413664\n",
      "Step 700:  0.0401511\n",
      "End of epoch 3:\n",
      "Training loss: 0.0474143 Validation loss: 0.0511156 Test loss: 0.044092\n",
      "Validation accuracy: 98.2973% Test accuracy: 98.5477%\n",
      "\n",
      "Step 100:  0.0347812\n",
      "Step 200:  0.0388869\n",
      "Step 300:  0.0338171\n",
      "Step 400:  0.0340464\n",
      "Step 500:  0.0302862\n",
      "Step 600:  0.0308792\n",
      "Step 700:  0.029324\n",
      "End of epoch 4:\n",
      "Training loss: 0.0330852 Validation loss: 0.0565706 Test loss: 0.0512994\n",
      "Validation accuracy: 98.3373% Test accuracy: 98.5076%\n",
      "\n",
      "Step 100:  0.0267218\n",
      "Step 200:  0.0288349\n",
      "Step 300:  0.0230754\n",
      "Step 400:  0.0300475\n",
      "Step 500:  0.018324\n",
      "Step 600:  0.0219187\n",
      "Step 700:  0.0181154\n",
      "End of epoch 5:\n",
      "Training loss: 0.0238388 Validation loss: 0.0596154 Test loss: 0.0507874\n",
      "Validation accuracy: 98.3373% Test accuracy: 98.6178%\n",
      "\n",
      "Step 100:  0.020709\n",
      "Step 200:  0.0256588\n",
      "Step 300:  0.0169438\n",
      "Step 400:  0.0217889\n",
      "Step 500:  0.0159239\n",
      "Step 600:  0.0152913\n",
      "Step 700:  0.0153328\n",
      "End of epoch 6:\n",
      "Training loss: 0.0187408 Validation loss: 0.0703206 Test loss: 0.0606686\n",
      "Validation accuracy: 98.0369% Test accuracy: 98.3874%\n",
      "\n",
      "Step 100:  0.0178029\n",
      "Step 200:  0.018169\n",
      "Step 300:  0.0172039\n",
      "Step 400:  0.0150871\n",
      "Step 500:  0.0154435\n",
      "Step 600:  0.0186088\n",
      "Step 700:  0.0128386\n",
      "End of epoch 7:\n",
      "Training loss: 0.0164101 Validation loss: 0.0561645 Test loss: 0.0511564\n",
      "Validation accuracy: 98.5477% Test accuracy: 98.6378%\n",
      "\n",
      "Step 100:  0.0125766\n",
      "Step 200:  0.0153758\n",
      "Step 300:  0.0141634\n",
      "Step 400:  0.0111105\n",
      "Step 500:  0.0116553\n",
      "Step 600:  0.018843\n",
      "Step 700:  0.0136509\n",
      "End of epoch 8:\n",
      "Training loss: 0.0138803 Validation loss: 0.0595637 Test loss: 0.0596535\n",
      "Validation accuracy: 98.4575% Test accuracy: 98.5978%\n",
      "\n",
      "Step 100:  0.00724609\n",
      "Step 200:  0.0121772\n",
      "Step 300:  0.0102408\n",
      "Step 400:  0.0158405\n",
      "Step 500:  0.0103786\n",
      "Step 600:  0.0126488\n",
      "Step 700:  0.0144344\n",
      "End of epoch 9:\n",
      "Training loss: 0.0118894 Validation loss: 0.0422014 Test loss: 0.0441602\n",
      "Validation accuracy: 98.8582% Test accuracy: 98.9383%\n",
      "\n",
      "Step 100:  0.00562199\n",
      "Step 200:  0.00712328\n",
      "Step 300:  0.0122937\n",
      "Step 400:  0.0108369\n",
      "Step 500:  0.00984049\n",
      "Step 600:  0.00953928\n",
      "Step 700:  0.007972\n",
      "End of epoch 10:\n",
      "Training loss: 0.00904576 Validation loss: 0.0677981 Test loss: 0.0592099\n",
      "Validation accuracy: 98.5677% Test accuracy: 98.5276%\n",
      "\n",
      "Step 100:  0.014665\n",
      "Step 200:  0.0121476\n",
      "Step 300:  0.00804126\n",
      "Step 400:  0.00865409\n",
      "Step 500:  0.00947725\n",
      "Step 600:  0.00858509\n",
      "Step 700:  0.00536331\n",
      "End of epoch 11:\n",
      "Training loss: 0.00954718 Validation loss: 0.0550587 Test loss: 0.0481985\n",
      "Validation accuracy: 98.6679% Test accuracy: 98.8081%\n",
      "\n",
      "Step 100:  0.00469527\n",
      "Step 200:  0.00834614\n",
      "Step 300:  0.0071321\n",
      "Step 400:  0.00749011\n",
      "Step 500:  0.00976351\n",
      "Step 600:  0.00535909\n",
      "Step 700:  0.0104423\n",
      "End of epoch 12:\n",
      "Training loss: 0.00763874 Validation loss: 0.074056 Test loss: 0.0752283\n",
      "Validation accuracy: 98.4976% Test accuracy: 98.4175%\n",
      "\n",
      "Step 100:  0.0111467\n",
      "Step 200:  0.0123875\n",
      "Step 300:  0.00548044\n",
      "Step 400:  0.00450763\n",
      "Step 500:  0.00798157\n",
      "Step 600:  0.00651308\n",
      "Step 700:  0.00839005\n",
      "End of epoch 13:\n",
      "Training loss: 0.00802619 Validation loss: 0.0695442 Test loss: 0.0531472\n",
      "Validation accuracy: 98.4776% Test accuracy: 98.8081%\n",
      "\n",
      "Step 100:  0.00820113\n",
      "Step 200:  0.00750125\n",
      "Step 300:  0.00381251\n",
      "Step 400:  0.00499725\n",
      "Step 500:  0.00903157\n",
      "Step 600:  0.0067073\n",
      "Step 700:  0.00600681\n",
      "End of epoch 14:\n",
      "Training loss: 0.00658765 Validation loss: 0.0437964 Test loss: 0.0447915\n",
      "Validation accuracy: 98.9383% Test accuracy: 98.9483%\n",
      "\n",
      "Step 100:  0.00278092\n",
      "Step 200:  0.0044073\n",
      "Step 300:  0.00409166\n",
      "Step 400:  0.00911895\n",
      "Step 500:  0.00681741\n",
      "Step 600:  0.00325923\n",
      "Step 700:  0.00322706\n",
      "End of epoch 15:\n",
      "Training loss: 0.00501531 Validation loss: 0.0674765 Test loss: 0.05176\n",
      "Validation accuracy: 98.6779% Test accuracy: 98.9784%\n",
      "\n",
      "Step 100:  0.00411079\n",
      "Step 200:  0.0077548\n",
      "Step 300:  0.00569947\n",
      "Step 400:  0.00387609\n",
      "Step 500:  0.00527607\n",
      "Step 600:  0.00597723\n",
      "Step 700:  0.0121964\n",
      "End of epoch 16:\n",
      "Training loss: 0.00642139 Validation loss: 0.0500517 Test loss: 0.0499258\n",
      "Validation accuracy: 98.758% Test accuracy: 99.0084%\n",
      "\n",
      "Step 100:  0.00357203\n",
      "Step 200:  0.00603462\n",
      "Step 300:  0.00522875\n",
      "Step 400:  0.00423476\n",
      "Step 500:  0.0039334\n",
      "Step 600:  0.00417391\n",
      "Step 700:  0.00266635\n",
      "End of epoch 17:\n",
      "Training loss: 0.00424588 Validation loss: 0.0513397 Test loss: 0.0465232\n",
      "Validation accuracy: 98.8782% Test accuracy: 99.0485%\n",
      "\n",
      "Step 100:  0.00226576\n",
      "Step 200:  0.00486262\n",
      "Step 300:  0.00781498\n",
      "Step 400:  0.00741137\n",
      "Step 500:  0.00341462\n",
      "Step 600:  0.00407924\n",
      "Step 700:  0.00349596\n",
      "End of epoch 18:\n",
      "Training loss: 0.00503378 Validation loss: 0.115479 Test loss: 0.0861809\n",
      "Validation accuracy: 98.2071% Test accuracy: 98.4275%\n",
      "\n",
      "Step 100:  0.00888631\n",
      "Step 200:  0.0077864\n",
      "Step 300:  0.00198882\n",
      "Step 400:  0.00309167\n",
      "Step 500:  0.00337943\n",
      "Step 600:  0.00135566\n",
      "Step 700:  0.00179227\n",
      "End of epoch 19:\n",
      "Training loss: 0.00402468 Validation loss: 0.0549646 Test loss: 0.0496891\n",
      "Validation accuracy: 98.8081% Test accuracy: 99.0585%\n",
      "\n",
      "Step 100:  0.0013605\n",
      "Step 200:  0.00038169\n",
      "Step 300:  0.000272483\n",
      "Step 400:  0.00344553\n",
      "Step 500:  0.00898297\n",
      "Step 600:  0.00755644\n",
      "Step 700:  0.00220217\n",
      "End of epoch 20:\n",
      "Training loss: 0.00344298 Validation loss: 0.0586753 Test loss: 0.0476838\n",
      "Validation accuracy: 98.7981% Test accuracy: 98.8982%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(20):\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    valid_acc  = []\n",
    "    test_loss  = []\n",
    "    test_acc   = []\n",
    "\n",
    "    for j in range(len(train_X)/batch_size):\n",
    "        start = j * batch_size\n",
    "        end   = (j+1) * batch_size\n",
    "        loss_, _ = sess.run([loss, train_op], feed_dict={X: train_X[start:end], Y: train_Y[start:end]})\n",
    "\n",
    "        train_loss.append(loss_)\n",
    "        \n",
    "        if j > 0 and j % 100 == 0:\n",
    "            print ('Step %d: ' % j), np.mean(train_loss[(j-100):j])\n",
    "\n",
    "    for j in range(len(valid_X)/batch_size):\n",
    "        start = j * batch_size\n",
    "        end   = (j+1) * batch_size\n",
    "        loss_, acc_ = sess.run([loss, accuracy], feed_dict={X: valid_X[start:end], Y: valid_Y[start:end]})\n",
    "\n",
    "        valid_loss.append(loss_)\n",
    "        valid_acc.append(acc_)\n",
    "\n",
    "    for j in range(len(test_X)/batch_size):\n",
    "        start = j * batch_size\n",
    "        end   = (j+1) * batch_size\n",
    "        loss_, acc_ = sess.run([loss, accuracy], feed_dict={X: test_X[start:end], Y: test_Y[start:end]})\n",
    "\n",
    "        test_loss.append(loss_)\n",
    "        test_acc.append(acc_)\n",
    "\n",
    "    print 'End of epoch %d:' % (i+1)\n",
    "    print 'Training loss:', np.mean(train_loss), \\\n",
    "          'Validation loss:', np.mean(valid_loss), \\\n",
    "          'Test loss:', np.mean(test_loss)\n",
    "    print ('Validation accuracy: %g%%' % (np.mean(valid_acc) * 100)), \\\n",
    "          ('Test accuracy: %g%%' % (np.mean(test_acc) * 100))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe50776e610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5079138d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Input\n",
    "this_input, this_label = random.sample(zip(test_X, test_Y), 1)[0]\n",
    "label = sess.run(predict_op, feed_dict={X: [this_input], Y: [np.zeros_like(this_label)]})\n",
    "imshow(np.reshape(this_input, (28, 28)), interpolation='none', cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print label[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
