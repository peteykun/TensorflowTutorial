{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def get_bias(shape):\n",
    "    return tf.Variable(np.zeros(shape), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = tf.placeholder(tf.float32, [None, 784])\n",
    "label  = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input layer to hidden layer\n",
    "W1 = get_weights([784, hidden_size])\n",
    "b1 = get_bias([hidden_size])\n",
    "\n",
    "# Hidden layer to output layer\n",
    "W2 = get_weights([hidden_size, 10])\n",
    "b2 = get_bias([10])\n",
    "\n",
    "# Activations\n",
    "hidden = tf.sigmoid(tf.matmul(input_, W1) + b1)\n",
    "output = tf.sigmoid(tf.matmul(hidden, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "clipped_output         = tf.clip_by_value(output, 1e-10, 1.0)\n",
    "clipped_1_minus_output = tf.clip_by_value(1 - output, 1e-10, 1.0)\n",
    "\n",
    "loss = -tf.reduce_sum(label * tf.log(clipped_output) + (1 - label) * tf.log(clipped_1_minus_output))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output, 1), tf.argmax(label, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Validation split\n",
    "valid_ratio = float(10)/55\n",
    "train_pairs = zip(mnist.train.images, mnist.train.labels)\n",
    "random.shuffle(train_pairs)\n",
    "train_X, train_Y = zip(*train_pairs[int(valid_ratio*len(train_pairs)):])\n",
    "valid_X, valid_Y = zip(*train_pairs[:int(valid_ratio*len(train_pairs))])\n",
    "\n",
    "# Test pairs\n",
    "test_X, test_Y = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 45000\n",
      "Validation: 10000\n",
      "Test: 10000\n"
     ]
    }
   ],
   "source": [
    "print 'Training:', len(train_X)\n",
    "print 'Validation:', len(valid_X)\n",
    "print 'Test:', len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1:\n",
      "Training loss: 141.475 Validation loss: 67.6503 Test loss: 65.8488\n",
      "Validation accuracy: 88.1711% Test accuracy: 88.9623%\n",
      "\n",
      "End of epoch 2:\n",
      "Training loss: 48.868 Validation loss: 39.3831 Test loss: 37.4876\n",
      "Validation accuracy: 91.2961% Test accuracy: 91.9171%\n",
      "\n",
      "End of epoch 3:\n",
      "Training loss: 34.1555 Validation loss: 32.1069 Test loss: 30.2752\n",
      "Validation accuracy: 92.3878% Test accuracy: 92.8285%\n",
      "\n",
      "End of epoch 4:\n",
      "Training loss: 28.5894 Validation loss: 28.4068 Test loss: 26.6187\n",
      "Validation accuracy: 93.1791% Test accuracy: 93.72%\n",
      "\n",
      "End of epoch 5:\n",
      "Training loss: 25.2039 Validation loss: 25.9441 Test loss: 24.1656\n",
      "Validation accuracy: 93.76% Test accuracy: 94.1707%\n",
      "\n",
      "End of epoch 6:\n",
      "Training loss: 22.7015 Validation loss: 24.0699 Test loss: 22.3005\n",
      "Validation accuracy: 94.2107% Test accuracy: 94.6314%\n",
      "\n",
      "End of epoch 7:\n",
      "Training loss: 20.6743 Validation loss: 22.5367 Test loss: 20.8084\n",
      "Validation accuracy: 94.4912% Test accuracy: 95.002%\n",
      "\n",
      "End of epoch 8:\n",
      "Training loss: 18.9572 Validation loss: 21.2512 Test loss: 19.5782\n",
      "Validation accuracy: 94.8117% Test accuracy: 95.2825%\n",
      "\n",
      "End of epoch 9:\n",
      "Training loss: 17.4746 Validation loss: 20.1603 Test loss: 18.5579\n",
      "Validation accuracy: 95.1222% Test accuracy: 95.4828%\n",
      "\n",
      "End of epoch 10:\n",
      "Training loss: 16.1885 Validation loss: 19.2236 Test loss: 17.7105\n",
      "Validation accuracy: 95.3526% Test accuracy: 95.7031%\n",
      "\n",
      "End of epoch 11:\n",
      "Training loss: 15.0602 Validation loss: 18.4123 Test loss: 16.9998\n",
      "Validation accuracy: 95.5529% Test accuracy: 95.8834%\n",
      "\n",
      "End of epoch 12:\n",
      "Training loss: 14.056 Validation loss: 17.7075 Test loss: 16.3965\n",
      "Validation accuracy: 95.7332% Test accuracy: 96.0236%\n",
      "\n",
      "End of epoch 13:\n",
      "Training loss: 13.1504 Validation loss: 17.0935 Test loss: 15.8785\n",
      "Validation accuracy: 95.9235% Test accuracy: 96.224%\n",
      "\n",
      "End of epoch 14:\n",
      "Training loss: 12.3262 Validation loss: 16.5589 Test loss: 15.4307\n",
      "Validation accuracy: 96.0637% Test accuracy: 96.3441%\n",
      "\n",
      "End of epoch 15:\n",
      "Training loss: 11.5716 Validation loss: 16.0954 Test loss: 15.0404\n",
      "Validation accuracy: 96.2941% Test accuracy: 96.4944%\n",
      "\n",
      "End of epoch 16:\n",
      "Training loss: 10.8787 Validation loss: 15.6944 Test loss: 14.6981\n",
      "Validation accuracy: 96.3842% Test accuracy: 96.6046%\n",
      "\n",
      "End of epoch 17:\n",
      "Training loss: 10.241 Validation loss: 15.3471 Test loss: 14.397\n",
      "Validation accuracy: 96.4643% Test accuracy: 96.6947%\n",
      "\n",
      "End of epoch 18:\n",
      "Training loss: 9.65152 Validation loss: 15.0443 Test loss: 14.1304\n",
      "Validation accuracy: 96.6046% Test accuracy: 96.7248%\n",
      "\n",
      "End of epoch 19:\n",
      "Training loss: 9.10392 Validation loss: 14.7783 Test loss: 13.894\n",
      "Validation accuracy: 96.6947% Test accuracy: 96.7548%\n",
      "\n",
      "End of epoch 20:\n",
      "Training loss: 8.59348 Validation loss: 14.5454 Test loss: 13.6858\n",
      "Validation accuracy: 96.7147% Test accuracy: 96.7648%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(20):\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    valid_acc  = []\n",
    "    test_loss  = []\n",
    "    test_acc   = []\n",
    "\n",
    "    for j in range(len(train_X)/batch_size):\n",
    "        start = j * batch_size\n",
    "        end   = (j+1) * batch_size\n",
    "        loss_, _ = sess.run([loss, train_op], feed_dict={input_: train_X[start:end], label: train_Y[start:end]})\n",
    "\n",
    "        train_loss.append(loss_)\n",
    "\n",
    "    for j in range(len(valid_X)/batch_size):\n",
    "        start = j * batch_size\n",
    "        end   = (j+1) * batch_size\n",
    "        loss_, acc_ = sess.run([loss, accuracy], feed_dict={input_: valid_X[start:end], label: valid_Y[start:end]})\n",
    "\n",
    "        valid_loss.append(loss_)\n",
    "        valid_acc.append(acc_)\n",
    "\n",
    "    for j in range(len(test_X)/batch_size):\n",
    "        start = j * batch_size\n",
    "        end   = (j+1) * batch_size\n",
    "        loss_, acc_ = sess.run([loss, accuracy], feed_dict={input_: test_X[start:end], label: test_Y[start:end]})\n",
    "\n",
    "        test_loss.append(loss_)\n",
    "        test_acc.append(acc_)\n",
    "\n",
    "    print 'End of epoch %d:' % (i+1)\n",
    "    print 'Training loss:', np.mean(train_loss), \\\n",
    "          'Validation loss:', np.mean(valid_loss), \\\n",
    "          'Test loss:', np.mean(test_loss)\n",
    "    print ('Validation accuracy: %g%%' % (np.mean(valid_acc)*100)), \\\n",
    "          ('Test accuracy: %g%%' % (np.mean(test_acc)*100))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f09480175d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPpAQwQcSIvhAQgQfSIjgAwn9P56KqcigcECLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0948d82650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Input\n",
    "this_input = random.sample(test_X, 1)[0]\n",
    "imshow(np.reshape(this_input, (28, 28)), interpolation='nearest', cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get output\n",
    "this_output = sess.run(output, feed_dict={input_: [this_input]})\n",
    "print np.argmax(this_output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
